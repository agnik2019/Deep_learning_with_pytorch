{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Managing The dataset"
      ],
      "metadata": {
        "id": "0J-Ox0wGrM9W"
      },
      "id": "0J-Ox0wGrM9W"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjKX5bpcrP4B",
        "outputId": "a56baa78-caa9-48ea-cbe8-ef410d51b0b0"
      },
      "id": "xjKX5bpcrP4B",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scp /content/drive/MyDrive/codebert/train.jsonl ./"
      ],
      "metadata": {
        "id": "A8zvmBnordum"
      },
      "id": "A8zvmBnordum",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!scp /content/drive/MyDrive/codebert/test.jsonl ./\n",
        "!scp /content/drive/MyDrive/codebert/valid.jsonl ./\n",
        "!scp /content/drive/MyDrive/codebert/codebase.jsonl ./"
      ],
      "metadata": {
        "id": "_VRyl7B4sHX7"
      },
      "id": "_VRyl7B4sHX7",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyuPvHGhsU1U",
        "outputId": "ed9f4105-0592-4085-b17d-f70eb71ef0e8"
      },
      "id": "SyuPvHGhsU1U",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "baf08253",
      "metadata": {
        "id": "baf08253"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import torch\n",
        "import json\n",
        "import numpy as np\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler,TensorDataset\n",
        "from transformers import (WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup,\n",
        "                  RobertaConfig, RobertaModel, RobertaTokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c7d24062",
      "metadata": {
        "id": "c7d24062"
      },
      "outputs": [],
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single training/test features for a example.\"\"\"\n",
        "    def __init__(self,\n",
        "                 code_tokens,\n",
        "                 code_ids,\n",
        "                 nl_tokens,\n",
        "                 nl_ids,\n",
        "                 url,\n",
        "\n",
        "    ):\n",
        "        self.code_tokens = code_tokens\n",
        "        self.code_ids = code_ids\n",
        "        self.nl_tokens = nl_tokens\n",
        "        self.nl_ids = nl_ids\n",
        "        self.url=url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7ff9c7ad",
      "metadata": {
        "id": "7ff9c7ad"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(js,tokenizer):\n",
        "    code_length = 256\n",
        "    nl_length = 128\n",
        "    code=' '.join(js['code_tokens'])\n",
        "    code_tokens=tokenizer.tokenize(code)[:code_length-2] # Remove examples that #tokens of documents is>256\n",
        "    code_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token] # adding cls and sep token\n",
        "    code_ids =  tokenizer.convert_tokens_to_ids(code_tokens)\n",
        "    padding_length = code_length - len(code_ids)\n",
        "    code_ids+=[tokenizer.pad_token_id]*padding_length\n",
        "    \n",
        "    nl=' '.join(js['docstring_tokens'])\n",
        "    nl_tokens=tokenizer.tokenize(nl)[:nl_length-2]\n",
        "    nl_tokens =[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
        "    nl_ids =  tokenizer.convert_tokens_to_ids(nl_tokens)\n",
        "    padding_length = nl_length - len(nl_ids)\n",
        "    nl_ids+=[tokenizer.pad_token_id]*padding_length    \n",
        "    \n",
        "    return InputFeatures(code_tokens,code_ids,nl_tokens,nl_ids,js['url'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "677f4d5d",
      "metadata": {
        "id": "677f4d5d"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer,file_path=None):\n",
        "        self.examples = []\n",
        "        data=[]\n",
        "        with open(file_path) as f:\n",
        "            for line in f:\n",
        "                line=line.strip()\n",
        "                js=json.loads(line)\n",
        "                data.append(js)\n",
        "\n",
        "        for js in data:\n",
        "            self.examples.append(convert_examples_to_features(js,tokenizer))\n",
        "            \n",
        "        if 'train' in file_path:\n",
        "            for idx, example in enumerate(self.examples[:3]):\n",
        "                print(\"*** Example ***\")\n",
        "                print(\"idx: {}\".format(idx))\n",
        "                print(\"code_tokens: {}\".format([x.replace('\\u0120','_') for x in example.code_tokens]))\n",
        "                print(\"code_ids: {}\".format(' '.join(map(str, example.code_ids))))\n",
        "                print(\"nl_tokens: {}\".format([x.replace('\\u0120','_') for x in example.nl_tokens]))\n",
        "                print(\"nl_ids: {}\".format(' '.join(map(str, example.nl_ids))))                             \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):   \n",
        "        return (torch.tensor(self.examples[i].code_ids),torch.tensor(self.examples[i].nl_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cc0834c4",
      "metadata": {
        "id": "cc0834c4"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYHTONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "aa90cc7b",
      "metadata": {
        "id": "aa90cc7b"
      },
      "outputs": [],
      "source": [
        "def train(model, tokenizer):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    print(\"starting\")\n",
        "    # get the args variable\n",
        "    train_data_file = \"train.jsonl\"\n",
        "    output_dir = \"./saved_models/python\"\n",
        "    learning_rate = 2e-5\n",
        "    num_train_epochs = 10\n",
        "    train_batch_size = 32\n",
        "    max_grad_norm = 1 # default\n",
        "    \n",
        "    print(\"getting ready for training !!\")\n",
        "    #get training dataset\n",
        "    train_dataset=TextDataset(tokenizer,train_data_file)\n",
        "    train_sampler = RandomSampler(train_dataset) # RandomSampler, Dataloader -> torch.utils.data\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size,num_workers=4)\n",
        "    \n",
        "    print(\"data loader is ready\")\n",
        "    \n",
        "    #get optimizer and scheduler\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,num_training_steps=len(train_dataloader)*num_train_epochs)\n",
        "\n",
        "    # Train!\n",
        "    print(\"***** Running training *****\")\n",
        "    print(\"  Num examples = %d\", len(train_dataset))\n",
        "    print(\"  Num Epochs = %d\", num_train_epochs)\n",
        "    print(\"  Total train batch size  = %d\", train_batch_size)\n",
        "    print(\"  Total optimization steps = %d\", len(train_dataloader)*num_train_epochs)\n",
        "    \n",
        "    # model.resize_token_embeddings(len(tokenizer))\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.zero_grad()\n",
        "    \n",
        "    model.train()\n",
        "    tr_num,tr_loss,best_mrr=0,0,0 \n",
        "    for idx in range(num_train_epochs): \n",
        "        for step,batch in enumerate(train_dataloader):\n",
        "            #get inputs\n",
        "            code_inputs = batch[0].to(device)\n",
        "            nl_inputs = batch[1].to(device)\n",
        "            #get code and nl vectors\n",
        "            code_vec = model(code_inputs=code_inputs)\n",
        "            nl_vec = model(nl_inputs=nl_inputs)\n",
        "            \n",
        "            #calculate scores and loss\n",
        "            scores=torch.einsum(\"ab,cb->ac\",nl_vec,code_vec)\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(scores, torch.arange(code_inputs.size(0), device=scores.device))\n",
        "            \n",
        "            #report loss\n",
        "            tr_loss += loss.item()\n",
        "            tr_num+=1\n",
        "            if (step+1)% 100==0:\n",
        "                print(\"epoch {} step {} loss {}\".format(idx,step+1,round(tr_loss/tr_num,5)))\n",
        "                tr_loss=0\n",
        "                tr_num=0\n",
        "            \n",
        "            #backward\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step() \n",
        "            \n",
        "        #evaluate    \n",
        "        results = evaluate(model, tokenizer, eval_when_training=True)\n",
        "        for key, value in results.items():\n",
        "            print(\"  %s = %s\", key, round(value,4))    \n",
        "            \n",
        "        #save best model\n",
        "        if results['eval_mrr']>best_mrr:\n",
        "            best_mrr=results['eval_mrr']\n",
        "            print(\"  \"+\"*\"*20)  \n",
        "            print(\"  Best mrr:%s\",round(best_mrr,4))\n",
        "            print(\"  \"+\"*\"*20)                          \n",
        "\n",
        "            checkpoint_prefix = 'checkpoint-best-mrr'\n",
        "            output_dir = os.path.join(output_dir, '{}'.format(checkpoint_prefix))                        \n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)         \n",
        "            model_to_save = model.module if hasattr(model,'module') else model\n",
        "            model_to_save.encoder.save_pretrained(output_dir)            \n",
        "            output_dir = os.path.join(output_dir, '{}'.format('model.bin')) \n",
        "            torch.save(model_to_save.state_dict(), output_dir) \n",
        "            print(\"Saving model checkpoint to %s\", output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc01652",
      "metadata": {
        "id": "ffc01652"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, tokenizer,file_name,eval_when_training=False):\n",
        "    #file_name = \"valid.jsonl\"\n",
        "    eval_batch_size = 64\n",
        "    codebase_file = \"codebase.jsonl\"\n",
        "    query_dataset = TextDataset(tokenizer,file_name)\n",
        "    query_sampler = SequentialSampler(query_dataset)\n",
        "    query_dataloader = DataLoader(query_dataset, sampler=query_sampler, batch_size=eval_batch_size,num_workers=4)\n",
        "    \n",
        "    code_dataset = TextDataset(tokenizer, codebase_file)\n",
        "    code_sampler = SequentialSampler(code_dataset)\n",
        "    code_dataloader = DataLoader(code_dataset, sampler=code_sampler, batch_size=eval_batch_size,num_workers=4)    \n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "        # multi-gpu evaluate\n",
        "    if n_gpu > 1 and eval_when_training is False:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    print(\"***** Running evaluation *****\")\n",
        "    print(\"  Num queries = %d\", len(query_dataset))\n",
        "    print(\"  Num codes = %d\", len(code_dataset))\n",
        "    print(\"  Batch size = %d\", eval_batch_size)\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    code_vecs=[] \n",
        "    nl_vecs=[]\n",
        "    for batch in query_dataloader:  \n",
        "        nl_inputs = batch[1].to(device)\n",
        "        with torch.no_grad():\n",
        "            nl_vec = model(nl_inputs=nl_inputs) \n",
        "            nl_vecs.append(nl_vec.cpu().numpy()) \n",
        "\n",
        "    for batch in code_dataloader:\n",
        "        code_inputs = batch[0].to(device)\n",
        "        with torch.no_grad():\n",
        "            code_vec= model(code_inputs=code_inputs)\n",
        "            code_vecs.append(code_vec.cpu().numpy())  \n",
        "    model.train()    \n",
        "    code_vecs=np.concatenate(code_vecs,0)\n",
        "    nl_vecs=np.concatenate(nl_vecs,0)\n",
        "\n",
        "    scores=np.matmul(nl_vecs,code_vecs.T)\n",
        "    \n",
        "    sort_ids=np.argsort(scores, axis=-1, kind='quicksort', order=None)[:,::-1]    \n",
        "    \n",
        "    nl_urls=[]\n",
        "    code_urls=[]\n",
        "    for example in query_dataset.examples:\n",
        "        nl_urls.append(example.url)\n",
        "        \n",
        "    for example in code_dataset.examples:\n",
        "        code_urls.append(example.url)\n",
        "        \n",
        "    ranks=[]\n",
        "    for url, sort_id in zip(nl_urls,sort_ids):\n",
        "        rank=0\n",
        "        find=False\n",
        "        for idx in sort_id[:1000]:\n",
        "            if find is False:\n",
        "                rank+=1\n",
        "            if code_urls[idx]==url:\n",
        "                find=True\n",
        "        if find:\n",
        "            ranks.append(1/rank)\n",
        "        else:\n",
        "            ranks.append(0)\n",
        "    \n",
        "    result = {\n",
        "        \"eval_mrr\":float(np.mean(ranks))\n",
        "    }\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "17659fae",
      "metadata": {
        "id": "17659fae"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class Model(nn.Module):   \n",
        "    def __init__(self, encoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.encoder = encoder\n",
        "      \n",
        "    def forward(self, code_inputs=None, nl_inputs=None): \n",
        "        if code_inputs is not None:\n",
        "            return self.encoder(code_inputs,attention_mask=code_inputs.ne(1))[1]\n",
        "        else:\n",
        "            return self.encoder(nl_inputs,attention_mask=nl_inputs.ne(1))[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"device: %s, n_gpu: %s\",device, n_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TseVjDU1z6tq",
        "outputId": "2321849d-b5f4-423d-af16-13525e955435"
      },
      "id": "TseVjDU1z6tq",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: %s, n_gpu: %s cuda 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "59ef30af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ef30af",
        "outputId": "1ff653d2-a002-41a1-9cf3-00dbadb2a3f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Set seed\n",
        "seed = 123456\n",
        "set_seed(seed)\n",
        "\n",
        "#build model\n",
        "config = RobertaConfig.from_pretrained(\"microsoft/codebert-base\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")    \n",
        "model=Model(model)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "lEZUw_Ax3Fn9"
      },
      "id": "lEZUw_Ax3Fn9"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5141627d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5141627d",
        "outputId": "32c450c6-5d76-42f0-8132-31dfc98b6be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting\n",
            "getting ready for training !!\n",
            "*** Example ***\n",
            "idx: 0\n",
            "code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_\"', 's', '\"', '_)', '_:', '_level', '_=', '_level', '_+', '_\"', '__', '\"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_\"', ';\"', '_)', '_[', '_0', '_]', '</s>']\n",
            "code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']\n",
            "nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "*** Example ***\n",
            "idx: 1\n",
            "code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_\"\"\"', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '.\"', '\"\"', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_\"\"\"', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '\"\"\"', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']\n",
            "code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']\n",
            "nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "*** Example ***\n",
            "idx: 2\n",
            "code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_\"', 'r', 'U', '\"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_\"', 'Input', '_file', '_is', '_closed', '.\"', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']\n",
            "code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']\n",
            "nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "data loader is ready\n",
            "***** Running training *****\n",
            "  Num examples = %d 248035\n",
            "  Num Epochs = %d 10\n",
            "  Total train batch size  = %d 32\n",
            "  Total optimization steps = %d 77520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 step 100 loss 2.52234\n",
            "epoch 0 step 200 loss 0.29045\n",
            "epoch 0 step 300 loss 0.23485\n",
            "epoch 0 step 400 loss 0.21591\n",
            "epoch 0 step 500 loss 0.21159\n",
            "epoch 0 step 600 loss 0.22245\n",
            "epoch 0 step 700 loss 0.17431\n",
            "epoch 0 step 800 loss 0.19053\n",
            "epoch 0 step 900 loss 0.15714\n",
            "epoch 0 step 1000 loss 0.17104\n",
            "epoch 0 step 1100 loss 0.18189\n",
            "epoch 0 step 1200 loss 0.16132\n",
            "epoch 0 step 1300 loss 0.16131\n",
            "epoch 0 step 1400 loss 0.15319\n",
            "epoch 0 step 1500 loss 0.14891\n",
            "epoch 0 step 1600 loss 0.17394\n",
            "epoch 0 step 1700 loss 0.14501\n",
            "epoch 0 step 1800 loss 0.15337\n",
            "epoch 0 step 1900 loss 0.15881\n",
            "epoch 0 step 2000 loss 0.14745\n",
            "epoch 0 step 2100 loss 0.14857\n",
            "epoch 0 step 2200 loss 0.15736\n",
            "epoch 0 step 2300 loss 0.13985\n",
            "epoch 0 step 2400 loss 0.15026\n",
            "epoch 0 step 2500 loss 0.15878\n",
            "epoch 0 step 2600 loss 0.14545\n",
            "epoch 0 step 2700 loss 0.12214\n",
            "epoch 0 step 2800 loss 0.15591\n",
            "epoch 0 step 2900 loss 0.14117\n",
            "epoch 0 step 3000 loss 0.13655\n",
            "epoch 0 step 3100 loss 0.10615\n",
            "epoch 0 step 3200 loss 0.13867\n",
            "epoch 0 step 3300 loss 0.12692\n",
            "epoch 0 step 3400 loss 0.12259\n",
            "epoch 0 step 3500 loss 0.1369\n",
            "epoch 0 step 3600 loss 0.11632\n",
            "epoch 0 step 3700 loss 0.11018\n",
            "epoch 0 step 3800 loss 0.10951\n",
            "epoch 0 step 3900 loss 0.11179\n",
            "epoch 0 step 4000 loss 0.12462\n",
            "epoch 0 step 4100 loss 0.12984\n",
            "epoch 0 step 4200 loss 0.14161\n",
            "epoch 0 step 4300 loss 0.11872\n",
            "epoch 0 step 4400 loss 0.14645\n",
            "epoch 0 step 4500 loss 0.14047\n",
            "epoch 0 step 4600 loss 0.11992\n",
            "epoch 0 step 4700 loss 0.12592\n",
            "epoch 0 step 4800 loss 0.10728\n",
            "epoch 0 step 4900 loss 0.128\n",
            "epoch 0 step 5000 loss 0.12121\n",
            "epoch 0 step 5100 loss 0.10754\n",
            "epoch 0 step 5200 loss 0.10636\n",
            "epoch 0 step 5300 loss 0.12083\n",
            "epoch 0 step 5400 loss 0.10864\n",
            "epoch 0 step 5500 loss 0.1162\n",
            "epoch 0 step 5600 loss 0.11678\n",
            "epoch 0 step 5700 loss 0.09729\n",
            "epoch 0 step 5800 loss 0.103\n",
            "epoch 0 step 5900 loss 0.12894\n",
            "epoch 0 step 6000 loss 0.11869\n",
            "epoch 0 step 6100 loss 0.10806\n",
            "epoch 0 step 6200 loss 0.11508\n",
            "epoch 0 step 6300 loss 0.1282\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-22906f1cec26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-ed4fcbe16604>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, tokenizer)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m#backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(model, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "tpu9Ve6O3Jaj"
      },
      "id": "tpu9Ve6O3Jaj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c835ac",
      "metadata": {
        "id": "04c835ac"
      },
      "outputs": [],
      "source": [
        "# evaluation on dataset\n",
        "results = {}\n",
        "output_dir=\"./saved_models/python\"\n",
        "checkpoint_prefix = 'checkpoint-best-mrr/model.bin'\n",
        "eval_dataset = \"valid.jsonl\"\n",
        "test_dataset = \"test.jsonl\"\n",
        "output_dir = os.path.join(output_dir, '{}'.format(checkpoint_prefix))  \n",
        "model.load_state_dict(torch.load(output_dir),strict=False)      \n",
        "model.to(device)\n",
        "result=evaluate( model, tokenizer, eval_dataset)\n",
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "    print(\"  %s = %s\", key, str(round(result[key],4)))\n",
        "\n",
        "## test\n",
        "result=evaluate( model, tokenizer, test_dataset)\n",
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "    print(\"  %s = %s\", key, str(round(result[key],4)))\n",
        "\n",
        "print(\"==========Result=============\")\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "fine-tuning code bert.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}